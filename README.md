# GAN을 통한 손글씨 폰트 제작(Capstone design 2021-2)
* 소프트웨어융합학과 2019102130 정세연

## Overview
* Needs, problems<br>
네이버 CLOVA OCR에서 진행했던 ‘나의 손글씨로 폰트 제작하기’ 프로젝트를 계기로 자신의 글씨체가 폰트로 출력되게 하는 것에 관심이 생겼다. 한글은 초성, 중성, 종성이 결합된 형태로 총 3192개의 음절을 생성해낼 수 있다. 현실적으로 손글씨를 폰트로 만들기 위해서는 이 수많은 음절에 대한 손글씨를 모두 입력 값으로 넣지 않고도 폰트를 만들어낼 수 있어야 한다. 이때 보다 적은 양의 음절 이미지 입력으로도 학습이 잘 이루어질 수 있도록 하는 알고리즘을 개발하기 위한 시도가 이루어지고 있다.
* Goals, objectives (evaluation)<br>
프로젝트의 장기적인 목표는 손글씨를 입력하여 폰트를 제작하여 주는 시스템을 만들어내는 것이다. 여러 종류의 폰트로 구성된 음절 이미지 데이터를 통해 모델을 학습 시켜서 손글씨를 입력 받아 폰트를 새롭게 생성해주는 모델을 자체적으로 구현해 본다.<br>
프로젝트의 장기적인 목표는 손글씨를 학습하여 폰트를 제작해주는 시스템을 만드는 것이다. 다양한 폰트의 음절 이미지를 수집하고 이렇게 수집한 음절 이미지 데이터를 입력으로 넣어 모델을 학습시킨다. 기존의 모델이 생성하는 손글씨 폰트와 실제 손글씨의 유사도를 바탕으로 성능을 평가한 후에 추가적인 작업을 포함한 모델의 성능을 비교하여 후자의 모델이 더 좋은 성능을 보이도록하는 것이 본 프로젝트의 목표이다.
기존의 모델의 결과물을 원본 소스코드의 결과물을 기준으로 예측해보았을 때, 폰트가 깔끔하게 출력되지 않고 노이즈가 많은 것을 확인할 수 있다. 따라서 폰트가 깔끔하게 출력되도록 후처리 작업을 추가하여 향상된 성능을 보이는 모델을 생성할 계획이다.<br>

## Schedule
|    Contents     | September |  October  |  November |  December | 
|-----------------|-----------|-----------|-----------|-----------|
|  데이터 수집       |    V     |           |           |           |
|  개발환경 구축     |     V     |           |           |           | 
|  데이터 전처리     |     V     |           |           |           |
|  사전학습모델 구현  |           |     V     |     V     |     V     |
|  성능 평가        |           |           |           |     V     |
|  성능 개선        |           |           |           |     V     |
|  데이터 후처리     |           |           |           |     V     |
|  개선 여부 확인    |           |           |           |     V     |

### 수행 방법
- Google Colaboratory
- pytorch
- model : GAN (zi2zi - Unet)
- training data : 저작권 없는 폰트 20가지 (최종 모델 사전 학습 기준)

## Results
* 데이터<br>
   Pre training 과정에서 사용한 학습 데이터는 저작권이 없는 폰트 20가지를 사용하였다. ttf형태의 폰트 파일에서 음절을 이미지로 저장하는 작업을 거쳐 모델이 이미지를 학습하고 이미지를 생성하는 형태로 학습을 진행하였다. 이후 transfer learning에서 학습한 손글씨는 직접 작성하였다. 학습하는 데이터는 학습하려는 폰트/손글씨 이미지와 음절 내의 초성, 중성, 종성의 위치 관계를 학습할 수 있는 고딕체 소스 이미지를 나란히 놓은 형태로 구성하였다. 개별 학습 데이터 예시는 다음과 같다.<br>
   ![20_10594](https://user-images.githubusercontent.com/65614582/147803102-516a57d7-1d3f-43f9-aca8-c577ebd1917c.png)<br>
   위의 데이터에서 음절 이미지에 해당하는 부분 만을 crop하여 사이즈를 동일하게 조정하고 여백을 추가하여 모든 음절 이미지가 유사한 크기로 중앙에 위치하도록 모델을 구성하였다.

* 모델 학습 결과 및 비교<br>
   1. 기존의 모델 학습 결과<br>
      **Pre-training 결과물**
      ![fake_samples-250-1000](https://user-images.githubusercontent.com/65614582/147804383-03df9e7f-ccf4-4cbb-accb-cfd2735f8815.png)<br>
      노이즈 제거, 대비 극대화, 테두리 제거 등의 작업을 통해 보다 개선된 결과물을 얻을 수 있을 것이라 생각하여, 이를 바탕으로 성능 개선 작업을 진행하였다. <br><br>
      **실제 손글씨 학습 결과물**
      <img width="1044" alt="스크린샷 2021-12-31 오후 9 12 24" src="https://user-images.githubusercontent.com/65614582/147822872-b531ca20-8506-40a3-b32d-18bc55ce9f97.png"><br>
      손글씨를 학습한 결과물의 경우 어떤 음절인지 알아볼 수 없는 형태인 경우가 많은 것을 확인할 수 있다. 이를 개선하기 위해 데이터셋을 새로 구성하고 모델의 파라미터 조정을 하였다.

      
   2. 성능 개선 후 모델 학습 결과<br>
      성능 개선을 위해 모델 파라미터 조정을 하였다. 또한 이전의 모델에서 40가지의 폰트로 사전학습 시켰을 때에 성능이 매우 떨어져서 학습 데이터셋을 새롭게 구성하였다. 20가지의 폰트로 각 폰트마다 2000가지의 음절을 랜덤하게 추출하여 학습하게 하였다. 또 노이즈 제거, 대비 극대화, 테두리 제거 등의 후처리 작업을 추가하였다.<br>
      또 사전학습 단계에서 L1 loss를 통한 학습을 250 epoch, constant loss를 통한 학습을 300epoch 진행한 모델의 성능이 가장 높아 이 모델만 선택하여 손글씨 학습을 진행하였다. <br>
      성능 개선을 위해 모델 파라미터 조정을 하였다. 또한 이전의 모델에서 40가지의 폰트로 사전학습 시켰을 때에 성능이 매우 떨어져서 학습 데이터셋을 새롭게 구성하였다. 20가지의 폰트로 각 폰트마다 2000가지의 음절을 랜덤하게 추출하여 학습하게 하였다. 또 노이즈 제거, 대비 극대화, 테두리 제거(음절 이미지 crop) 등의 후처리 작업을 추가하였다.<br>
      **실제 손글씨 학습 결과물**
      손글씨를 이미지로 학습하여 모델이 만들어낸 음절 이미지 결과는 다음 사진과 같다. 아래 이미지는 순차적으로 모델의 결과물, 후처리 후 결과물, 실제 손글씨이다. (손글씨 이미지의 경우 직접 작성한 글씨 이미지라서 원본의 화질이 결과물보다 높음)<br>
      ![IMG_0540](https://user-images.githubusercontent.com/65614582/147822146-66ddb4ba-3a14-4a9e-a1a8-f8dc5f0368a8.jpg)<br>
      





## Conclusion
시간 상의 문제로 사전학습 단계에서 총 550, transfer learning에서 2950 epoch을 학습 시켰는데, 더 학습 시킨다면 초기 모델 결과물이 더욱 좋을것으로 예상된다. 또한 사전 학습 데이터인 폰트이미지를 구성할 때에 저작권의 문제가 없는 폰트를 통해 학습을 시키다 보니, 손글씨와 유사한 형태의 폰트가 적었다. 이 때문에 손글씨를 학습할 때 모델의 성능을 높이는 것이 어려웠다고 판단된다. 학습 데이터셋의 폰트를 고딕, 바탕체와 유사한 폰트가 아니라 좀 더 독특한 형태인 글씨로 학습을 시킨다면 더 좋을 것이라 생각한다. 예상한 것 만큼의 성능 개선을 하지는 못했지만 기존 모델이 가진 문제를 해결하는 과정에서 일정이 많이 변경되어, 향후 모델을 더 개선할 계획을 갖고 있다. 모델이 학습하는 데이터를 구성하는 과정을 개선하고 사용하는 데이터를 손글씨와의 연관성이 높은 폰트로 구성할 수 있도록 할 예정이며 데이터 전처리 과정을 추가하고 data augmentation 과정을 추가하는 등의 방식으로 모델 성능을 더 향상시키고자 한다.

## Reports
* Midterm: [Report](REPORT/데이터분석캡스톤디자인02(중간보고서_정세연).pdf)
* Final: [Report](REPORT/데이터분석캡스톤디자인03(결과보고서_정세연).pdf)
